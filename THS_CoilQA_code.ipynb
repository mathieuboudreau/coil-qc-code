{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spinal-cord-7t/coil-qc-code/blob/main/THS_CoilQA_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f5a7e1",
      "metadata": {
        "id": "31f5a7e1"
      },
      "source": [
        "# Python analysis code for the CoilQA portion of the Traveling Spine Study\n",
        "\n",
        "## Expected input data structure\n",
        "\n",
        "## This notebook expects the input data to be structured in the following way:\n",
        "\n",
        "### All data is converted from DICOM into NIFTI format using dcm2niix, with the following flags: \"-f %s_%p -z y\", with the exception of the GRE scans, which are converted using the flags \"-f %s_%p -z y -m o\". The expected output of this are filenames that start with a number, indicating the scan number (in order of reconstruction), and continue with an alphanumeric string indicating the name of the scan. The GRE scans are adittionally converted to preserve the RX-coil uncombined reconstruction. NB! the GRE scans have to be separated and converted separately!\n",
        "\n",
        "### For each subject, the resulting .nii.gz and .json files are then grouped into directories corresponding with the scans (so for example, the TFL_B1map scan results in three pairs of files, all of which are in one directory). Subjects are named as SubL, SubR, SubD, or Spinoza6, respectively. RF shimmed acquisitions, if they exist, are put into an RFSHIM subdirectory.\n",
        "\n",
        "\n",
        "\n",
        "### The subjects are grouped according to the site of data acquisition.\n",
        "\n",
        "### The end result is, for SubL acquired at site MGH, the following:\n",
        "#### MGH\n",
        "####         SubL\n",
        "####                  COILQA_SAG_LARGE\n",
        "####                  COILQA_SAG_SMALL\n",
        "####                  COILQA_TRA\n",
        "####                  DREAM_LARGE\n",
        "####                  DREAM_MEDIUM\n",
        "####                  DREAM_MEDIUM_066  ---> this scan is the one acquired with 66.6% of the optimal Reference Voltage\n",
        "####                  DREAM_MEDIUM_HWLIMIT  ---> this scan is the one acquired with the hardware limit Reference Voltage. In case that 150% of the reference Voltage would be possible to acquire, this would be called DREAM_MEDIUM_150\n",
        "####                  GRE ---> this folder contains both the combined and uncombined scans\n",
        "####                  MP2RAGE\n",
        "####                  TFL_B1 ---> this folder contains the B1+ map acquired without the Optimal Reference Voltage\n",
        "####                  TFL_B1_C3C4 ---> This folder contains the B1+ map acquired with the Optimal Reference Voltage\n",
        "####                  TFL_RFMAP ---> This folder is optional and is comes from in the RF shimming step\n",
        "####                  RFSHIM ---> This folder contains the B1+ shimmed scans, wich always include the following:\n",
        "####                                COILQA_SAG_LARGE ---> Same scan as the first folder, but acquired using RF shimming\n",
        "####                                GRE ---> Same scan as the unshimmed GRE folder, but acquired using RF shimming\n",
        "####                                TFL_RFMAP ---> Acquired using RF shimming\n",
        "\n",
        "\n",
        "## Sanity checks\n",
        "\n",
        "### There is currently one sanity check in the notebook, using the function \"RefVolChecker\". This will print to a table the reference voltage of each scan, and check wether they have been acquired using the Optimal Reference Voltage, which is defined as the Reference Voltage of the TFL_B1_C3C4 scan.\n",
        "\n",
        "### Another sanity check might be needed to check Table Positions, but that requires working on the DICOM data\n",
        "\n",
        "## Processing notes\n",
        "\n",
        "### In order to keep processed and unprocessed data separate, all processed data is stored under a \"PROCESSING\" master directory, where the directory strucutre of the original data is preserved. That is, when processing THS_DATA/MGH/SubL/MP2RAGE, all processed data, all segmentation, etc, etc, will be put under /THS_DATA/PROCESSING/MGH/SubL/MP2RAGE\n",
        "\n",
        "### The notebook is configured such that each scan of each subject can be analyzed independently\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa4be971",
      "metadata": {
        "id": "aa4be971"
      },
      "source": [
        "# Initial setup: Imports and installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a56c6b5b",
      "metadata": {
        "id": "a56c6b5b"
      },
      "outputs": [],
      "source": [
        "# Initial setup: importing modules\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import subprocess\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from tabulate import tabulate\n",
        "import nibabel as nib\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d278efad",
      "metadata": {
        "id": "d278efad"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import sys\n",
        "\n",
        "# Ask user for OSF login information\n",
        "osf_username = input(\"Enter OSF username: \")\n",
        "osf_password = input(\"Enter OSF password: \")\n",
        "%env OSF_USERNAME={osf_username}\n",
        "%env OSF_PASSWORD={osf_password}\n",
        "\n",
        "sys.stdout.flush()\n",
        "clear_output()\n",
        "sys.stdout.flush()\n",
        "\n",
        "sites_dict = {\n",
        "    \"MGH\": \"kgsbz\",\n",
        "    \"MNI\": \"5qapx\",\n",
        "}\n",
        "\n",
        "site_selection_text = \"\"\n",
        "for site_index, site_name in enumerate(sites_dict.keys()):\n",
        "    site_selection_text += str(site_index) + \" - \" + site_name + \"\\n\"\n",
        "site_selection_text += \"Enter site index: \"\n",
        "site_name = list(sites_dict.keys())[int(input(site_selection_text))]\n",
        "\n",
        "# osfclient installation from GitHub\n",
        "! git clone https://github.com/osfclient/osfclient\n",
        "! pip install /content/osfclient\n",
        "print(\"osfclient installed\")\n",
        "\n",
        "# Downloading data archive from OSF using osfclient\n",
        "archive = \"/content/osfclient/\" + site_name + \".zip\"\n",
        "! osf -p {sites_dict[site_name]} fetch /{site_name}.zip {archive}\n",
        "\n",
        "# Unzipping archive\n",
        "import zipfile\n",
        "with zipfile.ZipFile(archive, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/Traveling_Spines_7T/\")\n",
        "\n",
        "print(\"Downloaded files from OSF\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Spinal cord toolbox (SCT): This tool is used to for most of our processing, including image registration\n",
        "# Website: https://spinalcordtoolbox.com/\n",
        "!git clone --depth 1 --branch 5.3.0 https://github.com/spinalcordtoolbox/spinalcordtoolbox /content/spinalcordtoolbox\n",
        "os.chdir(\"/content/spinalcordtoolbox\")\n",
        "!yes | /content/spinalcordtoolbox/install_sct\n",
        "os.environ[\"PATH\"] += \":/content/spinalcordtoolbox/bin\"\n",
        "os.environ[\"SCT_DIR\"] = \"/content/spinalcordtoolbox\"\n",
        "os.chdir(\"/\")\n",
        "print(\"SCT installed\")\n",
        "\n",
        "# NIIMATH: since the sct_math function used in the \"Registration to PAM50 template\" is configured for 3D images, niimath\n",
        "# is used to perform a few image operations on 4D images\n",
        "# Github: https://github.com/rordenlab/niimath\n",
        "os.chdir(\"/content/\")\n",
        "!curl -fLO https://github.com/rordenlab/niimath/releases/download/v1.0.20211212/niimath_lnx.zip\n",
        "os.makedirs(\"/content/niimath/\", exist_ok=True)\n",
        "!unzip -o niimath_lnx.zip -d /content/niimath\n",
        "os.environ[\"PATH\"] += \":/content/niimath\"\n",
        "os.environ[\"FSLOUTPUTTYPE\"] = \"NIFTI_GZ\"\n",
        "print(\"NIIMATH installed\")"
      ],
      "metadata": {
        "id": "ao6cmFDlBRR4"
      },
      "id": "ao6cmFDlBRR4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "250c48e5",
      "metadata": {
        "id": "250c48e5"
      },
      "source": [
        "## Helper functions\n",
        "\n",
        "### Helper functions are collected here\n",
        "\n",
        "### find_scan_dir will return the path of any scan, as long as it exists\n",
        "\n",
        "### find_matching_nii_json_pairs will return the nifti file corresponding to a JSON with a specific keyword-location  info. For example, to get the UNI image of the MP2RAGE scan, the keyword would be 'UNI' and the keywordlocation would be 'ImageType'\n",
        "\n",
        "### run_subprocess is just a wrapper to run subprocesses (that is, calls to sct, niimath, etc) with a bit more convenience. NB! output is MUTED unless an errror occurs!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54be1683",
      "metadata": {
        "id": "54be1683"
      },
      "outputs": [],
      "source": [
        "# Helper function to return the directory path of a specific scan. Expected inputs are the root path (so either\n",
        "# THS_DATA or PROCESSING), the site name (MGH, MNI, NTNU, etc), the subject name (SubL, SubR, SubD, Sinoza6) and the name\n",
        "# of the scan directory\n",
        "\n",
        "def find_scan_dir(root_dir, site_name, subject_name, scan_name):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        if site_name in dirs:\n",
        "            site_path = os.path.join(root, site_name)\n",
        "            subject_path = os.path.join(site_path, subject_name)\n",
        "            scan_path = os.path.join(subject_path, scan_name)\n",
        "            if os.path.exists(scan_path):\n",
        "                return scan_path\n",
        "            else:\n",
        "                return f\"Error: {scan_name} not found in {subject_name}\"\n",
        "        else:\n",
        "            return f\"Error: {subject_name} not found in {site_name}\"\n",
        "    return f\"Error: {site_name} not found\"\n",
        "\n",
        "\n",
        "# Helper function to find a specific string in a specific location in a  JSON and return the matching nifti filename\n",
        "def find_matching_nii_json_pairs(directory_path, keyword, keywordlocation):\n",
        "    nii_filename = []\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith(\".json\"):\n",
        "            json_file_path = os.path.join(directory_path, filename)\n",
        "            nii_file_path = os.path.join(directory_path, filename.replace(\".json\", \".nii.gz\"))\n",
        "\n",
        "            if os.path.exists(nii_file_path):\n",
        "                with open(json_file_path, 'r') as json_file:\n",
        "                    data = json.load(json_file)\n",
        "                    if keywordlocation in data and keyword in data[keywordlocation]:\n",
        "                        nii_filename.append(nii_file_path)\n",
        "\n",
        "    if not nii_filename:\n",
        "        raise ValueError(\"No matching nii.gz files found.\")\n",
        "\n",
        "    return nii_filename\n",
        "\n",
        "\n",
        "# Helper function for subprocesses\n",
        "def run_subprocess(cmd):\n",
        "    \"\"\"Wrapper for ``subprocess.run()`` that enables to input ``cmd`` as a full string (easier for debugging).\n",
        "    Args:\n",
        "        cmd (string): full command to be run on the command line\n",
        "    \"\"\"\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            cmd.split(' '),\n",
        "            text=True,\n",
        "            check=True,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "        )\n",
        "    except subprocess.CalledProcessError as err:\n",
        "        print(f\"Return code: {err.returncode}\")\n",
        "        print(\"Output:\", err.output)\n",
        "        raise\n",
        "\n",
        "# This helper function checks if the MP2RAGE-derived scans necessary to process another scan are present\n",
        "def MP2RAGE_checker(root_dir,site_name,subject_name,scan_name):\n",
        "    scan_name='MP2RAGE' #ugly hack to force the function to always look for an MP2RAGE scan\n",
        "    MP2RAGE_PATH = find_scan_dir(root_dir,site_name,subject_name,scan_name)\n",
        "    MP2RAGE_UNI_filename = find_matching_nii_json_pairs(MP2RAGE_PATH, 'UNI', 'ImageType')[0]\n",
        "    MP2RAGE_PROCESSING_PATH=os.path.join(root_dir,'Processing',site_name,subject_name,scan_name)\n",
        "    MP2RAGE_UNI_maskfilename=os.path.join(MP2RAGE_PROCESSING_PATH,MP2RAGE_UNI_filename.split('.')[0].split('/')[-1]+'_mask.nii.gz')\n",
        "\n",
        "    if not os.path.isfile(MP2RAGE_UNI_maskfilename) and os.path.isfile(MP2RAGE_UNI_filename):\n",
        "        return f\"The MP2RAGE derived mask has not been found. Please run the MP2RAGE processing block first!\"\n",
        "    elif not os.path.isfile(MP2RAGE_UNI_filename):\n",
        "        return f\"The MP2RAGE UNI file has not been found. Please check your data directories!\"\n",
        "    else:\n",
        "        return [MP2RAGE_UNI_filename,MP2RAGE_UNI_maskfilename]\n",
        "\n",
        "\n",
        "# This helper function will get the WA column from the CSV files outputted by sct_extract_metric. Could probably be\n",
        "# rationalized to not use Pandas\n",
        "\n",
        "def signal_extractor_from_csv(csv_filename):\n",
        "  ## Load the CSV file into a Pandas DataFrame\n",
        "  dataframe=pd.read_csv(csv_filename, index_col='Slice (I->S)')\n",
        "  ## Convert all the strings (123.4242, etc) of the WA column into actual numerical values\n",
        "  dataframe['WA()'] = pd.to_numeric(dataframe['WA()'], errors='coerce')\n",
        "  WA_matrix=dataframe['WA()'].to_numpy()\n",
        "  return WA_matrix\n",
        "\n",
        "# Extracts the FA from a json file\n",
        "def extract_FA(json_file): #this function will extract the TxRefAmp value of the json file, which is\n",
        "    # the reference voltage\n",
        "    with open(json_file, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "        return data.get(\"FlipAngle\", \"N/A\")\n",
        "\n",
        "# Extracts the Reference Voltage from a json file\n",
        "def extract_tx_ref_amp(json_file): #this function will extract the TxRefAmp value of the json file, which is\n",
        "    # the reference voltage\n",
        "    with open(json_file, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "        return data.get(\"TxRefAmp\", \"N/A\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f14e3f7",
      "metadata": {
        "id": "3f14e3f7"
      },
      "source": [
        "## Sanity check for Reference Voltage\n",
        "\n",
        "### This will print to a table the reference voltage of each scan, and check wether they have been acquired using the Optimal Reference Voltage, which is defined as the Reference Voltage of the TFL_B1_C3C4 scan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c53933",
      "metadata": {
        "id": "94c53933"
      },
      "outputs": [],
      "source": [
        "#Sanity checker for Reference Voltage\n",
        "\n",
        "def extract_tx_ref_amp(json_file): #this function will extract the TxRefAmp value of the json file, which is\n",
        "    # the reference voltage\n",
        "    with open(json_file, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "        return data.get(\"TxRefAmp\", \"N/A\")\n",
        "\n",
        "def find_first_json_files(root_folder):\n",
        "    json_files = {}\n",
        "\n",
        "    for root, dirs, files in os.walk(root_folder):\n",
        "        dirs[:] = [d for d in dirs if \"RFSHIM\" not in d]\n",
        "        for file in files:\n",
        "            if file.endswith(\".json\"):\n",
        "                dir_path = os.path.basename(root)\n",
        "                if dir_path not in json_files:\n",
        "                    json_files[dir_path] = os.path.join(root, file)\n",
        "\n",
        "    return json_files\n",
        "\n",
        "def RefVolChecker(root_folder, target_folder):\n",
        "    json_files = find_first_json_files(root_folder)\n",
        "    table_data = []\n",
        "\n",
        "    target_tx_ref_amp = None\n",
        "    if target_folder in json_files:\n",
        "        target_tx_ref_amp = extract_tx_ref_amp(json_files[target_folder])\n",
        "\n",
        "    sorted_json_files = {k: json_files[k] for k in sorted(json_files)}\n",
        "\n",
        "    for dir_name, json_file in sorted_json_files.items():\n",
        "        tx_ref_amp = extract_tx_ref_amp(json_file)\n",
        "        checkbox_text = \"YES\" if tx_ref_amp == target_tx_ref_amp else \"\"\n",
        "        table_data.append([dir_name, tx_ref_amp, checkbox_text])\n",
        "\n",
        "    table_headers = [\"Folder Name\", \"TxRefAmp\", \"Optimal RefVol for C3/C4\"]\n",
        "\n",
        "    combined_table = tabulate(table_data, headers=table_headers, tablefmt=\"grid\")\n",
        "\n",
        "    print(\"\\nReference Voltage Sanity Check:\")\n",
        "    print(combined_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86aabad5",
      "metadata": {
        "id": "86aabad5"
      },
      "source": [
        "# MP2RAGE processing\n",
        "\n",
        "## Here, the following steps are carried out:\n",
        "\n",
        "## First, the spinal cord is segmented from the UNI image of the MP2RAGE scan\n",
        "\n",
        "## Then, the cervical levels are found using sct_label_vertebrae and the INV2 scan (it works better with that)\n",
        "\n",
        "## Third, the labeling is restricted between C1 and C7 (can be modified by the user)\n",
        "\n",
        "## Last, a mask is generated using the segmention\n",
        "\n",
        "## The QC output for the first two steps is visualised for the user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a691d8",
      "metadata": {
        "id": "b4a691d8"
      },
      "outputs": [],
      "source": [
        "# Step 1: Setting all the user-defined variables\n",
        "root_dir='/content/Traveling_Spines_7T'\n",
        "subject_name = \"Sub\" + input(\"Select a subject (D/R/L): \").strip()\n",
        "scan_name_MP2RAGE='MP2RAGE'\n",
        "\n",
        "# Where to restrict the segmentation\n",
        "Upperlimit_MP2RAGE=1 #Corresponds to C1; ADJUST AS NEEDED\n",
        "Lowerlimit_MP2RAGE=7 #Corresponds to C7; ADJUST AS NEEDED\n",
        "\n",
        "# How big to draw the mask\n",
        "masksize_MP2RAGE_mm=30 #Corresponds to the diameter of the cylindrical mask, IN MM, NOT VOXELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc2a3ca",
      "metadata": {
        "id": "4bc2a3ca"
      },
      "outputs": [],
      "source": [
        "# Step 2: select the UNI image and the INV2 image (labeling works much better on INV2)\n",
        "\n",
        "MP2RAGE_PATH = find_scan_dir(root_dir,site_name,subject_name,scan_name_MP2RAGE)\n",
        "\n",
        "MP2RAGE_UNI_filename = find_matching_nii_json_pairs(MP2RAGE_PATH, 'UNI', 'ImageType')[0]\n",
        "MP2RAGE_INV2_filename = find_matching_nii_json_pairs(MP2RAGE_PATH, 'INV2', 'SeriesDescription')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eedb0ce",
      "metadata": {
        "id": "0eedb0ce"
      },
      "outputs": [],
      "source": [
        "# Step 3: Predefine filenames and paths for PROCESSING\n",
        "MP2RAGE_PROCESSING_PATH=os.path.join(root_dir,'Processing',site_name,subject_name,scan_name_MP2RAGE)\n",
        "if not os.path.isdir(MP2RAGE_PROCESSING_PATH):\n",
        "    os.makedirs(MP2RAGE_PROCESSING_PATH)\n",
        "\n",
        "QCfilepath=os.path.join(MP2RAGE_PROCESSING_PATH,'qc')\n",
        "MP2RAGE_UNI_segfilename=os.path.join(MP2RAGE_PROCESSING_PATH,MP2RAGE_UNI_filename.split('.')[0].split('/')[-1]+'_seg.nii.gz')\n",
        "MP2RAGE_UNI_labelfilename=os.path.join(MP2RAGE_PROCESSING_PATH,MP2RAGE_UNI_filename.split('.')[0].split('/')[-1]+'_seg_labeled.nii.gz')\n",
        "MP2RAGE_UNI_labelfilename_dilated=os.path.join(MP2RAGE_PROCESSING_PATH,MP2RAGE_UNI_filename.split('.')[0].split('/')[-1]+'_seg_labeled_dil.nii.gz')\n",
        "MP2RAGE_UNI_labelfilename_restricted=os.path.join(MP2RAGE_PROCESSING_PATH,MP2RAGE_UNI_filename.split('.')[0].split('/')[-1]+'_seg_labeled_dil_restrict.nii.gz')\n",
        "MP2RAGE_UNI_maskfilename=os.path.join(MP2RAGE_PROCESSING_PATH,MP2RAGE_UNI_filename.split('.')[0].split('/')[-1]+'_mask.nii.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3643d094",
      "metadata": {
        "id": "3643d094"
      },
      "outputs": [],
      "source": [
        "#Step 4: segmenting and labeling the spinal cord\n",
        "\n",
        "\n",
        "# Segment the spinal cord\n",
        "run_subprocess(f\"sct_deepseg_sc -i {MP2RAGE_UNI_filename} -c t1 -qc {QCfilepath} -kernel 3d -o {MP2RAGE_UNI_segfilename}\")\n",
        "\n",
        "# Label the vertebrae\n",
        "#run_subprocess(f\"sct_label_vertebrae -i {MP2RAGE_INV2_filename} -s {MP2RAGE_UNI_segfilename} -c t1 -qc {QCfilepath} -ofolder {MP2RAGE_PROCESSING_PATH}\")\n",
        "! sct_label_vertebrae -i {MP2RAGE_INV2_filename} -s {MP2RAGE_UNI_segfilename} -c t1 -qc {QCfilepath} -ofolder {MP2RAGE_PROCESSING_PATH}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "877279c9",
      "metadata": {
        "id": "877279c9"
      },
      "outputs": [],
      "source": [
        "#Step 5: Restricting the segmentation and creating a mask\n",
        "\n",
        "# Dilating the label file, to make sure it fits whatever mask the user desires\n",
        "run_subprocess(f\"sct_maths -i {MP2RAGE_INV2_labelfilename} -o {MP2RAGE_INV2_labelfilename_dilated} -dilate 15 -dim=2 -shape=disk\")\n",
        "\n",
        "#Restricting the labelfile and binarizing it\n",
        "#run_subprocess(f\"sct_maths -i {MP2RAGE_UNI_labelfilename_dilated} -o {MP2RAGE_UNI_labelfilename_restricted} -thr {Upperlimit_MP2RAGE} -uthr {Lowerlimit_MP2RAGE}\")\n",
        "#run_subprocess(f\"sct_maths -i {MP2RAGE_UNI_labelfilename_restricted} -o {MP2RAGE_UNI_labelfilename_restricted} -bin {Upperlimit_MP2RAGE-1}\")\n",
        "\n",
        "#Creating a mask based on the segmentation\n",
        "run_subprocess(f\"sct_create_mask -i {MP2RAGE_INV2_filename} -p centerline,{MP2RAGE_INV2_segfilename} -f cylinder -size {masksize_MP2RAGE_mm}mm -o {MP2RAGE_INV2_maskfilename}\")\n",
        "\n",
        "# And restricting in to the levels specified by the user\n",
        "#run_subprocess(f\"sct_maths -i {MP2RAGE_UNI_maskfilename} -o {MP2RAGE_UNI_maskfilename} -mul {MP2RAGE_UNI_labelfilename_restricted}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bbd0f8b",
      "metadata": {
        "id": "0bbd0f8b"
      },
      "outputs": [],
      "source": [
        "# Step 6: QC visualisation step\n",
        "QA_image_path_deepseg=QA_image_path=os.path.join(QCfilepath,MP2RAGE_PROCESSING_PATH.split('/')[-3],\n",
        "                                         MP2RAGE_PROCESSING_PATH.split('/')[-2],\n",
        "                                         MP2RAGE_PROCESSING_PATH.split('/')[-1], 'sct_deepseg_sc')\n",
        "QA_image_path_deepseg=os.path.join(QA_image_path_deepseg,sorted(os.listdir(QA_image_path_deepseg))[-1]) #necessary to ensure the latest result is shown\n",
        "QA_image_background_deepseg=os.path.join(QA_image_path_deepseg,'bkg_img.png')\n",
        "QA_image_foreground_deepseg=os.path.join(QA_image_path_deepseg,'overlay_img.png')\n",
        "\n",
        "QA_image_path_label=os.path.join(QCfilepath,MP2RAGE_PROCESSING_PATH.split('/')[-3],\n",
        "                                         MP2RAGE_PROCESSING_PATH.split('/')[-2],\n",
        "                                         MP2RAGE_PROCESSING_PATH.split('/')[-1], 'sct_label_vertebrae')\n",
        "QA_image_path_label=os.path.join(QA_image_path_label,sorted(os.listdir(QA_image_path_label))[-1]) #necessary to ensure the latest result is shown\n",
        "QA_image_background_label=os.path.join(QA_image_path_label,'bkg_img.png')\n",
        "QA_image_foreground_label=os.path.join(QA_image_path_label,'overlay_img.png')\n",
        "\n",
        "image_paths_deepseg = [QA_image_background_deepseg,QA_image_foreground_deepseg]\n",
        "# Open and load all the images\n",
        "images = [Image.open(image_path) for image_path in image_paths_deepseg]\n",
        "# Get the dimensions of the first image\n",
        "width, height = images[0].size\n",
        "# Create a new blank image to overlay onto\n",
        "overlay_image = Image.new('RGBA', (width, height), (0, 0, 0, 0))\n",
        "# Overlay each image onto the blank image\n",
        "for image in images:\n",
        "    overlay_image = Image.alpha_composite(overlay_image, image.convert('RGBA'))\n",
        "# Convert the PIL image to a NumPy array\n",
        "overlay_array = np.array(overlay_image)\n",
        "# Display the overlaid image using matplotlib\n",
        "plt.imshow(overlay_array)\n",
        "plt.axis('off')  # Turn off axis labels and ticks\n",
        "plt.show()\n",
        "\n",
        "image_paths_label = [QA_image_background_label,QA_image_foreground_label]\n",
        "# Open and load all the images\n",
        "images = [Image.open(image_path) for image_path in image_paths_label]\n",
        "# Get the dimensions of the first image\n",
        "width, height = images[0].size\n",
        "# Create a new blank image to overlay onto\n",
        "overlay_image = Image.new('RGBA', (width, height), (0, 0, 0, 0))\n",
        "# Overlay each image onto the blank image\n",
        "for image in images:\n",
        "    overlay_image = Image.alpha_composite(overlay_image, image.convert('RGBA'))\n",
        "# Convert the PIL image to a NumPy array\n",
        "overlay_array = np.array(overlay_image)\n",
        "# Display the overlaid image using matplotlib\n",
        "plt.imshow(overlay_array)\n",
        "plt.axis('off')  # Turn off axis labels and ticks\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C4E4fKAY_it9"
      },
      "id": "C4E4fKAY_it9"
    },
    {
      "cell_type": "markdown",
      "id": "41774a01",
      "metadata": {
        "id": "41774a01"
      },
      "source": [
        "# TFL_B1map processing\n",
        "\n",
        "## Here, the following steps are carried out:\n",
        "\n",
        "## First, the anatomical and B1+ maps of the TFL_B1map scan acquired with Optimal Reference Voltage are identified\n",
        "\n",
        "## Second, the anatomical is coregistered to the MP2RAGE scan, and the mask derived from the MP2RAGE scan is warped to the space of the B1+ map\n",
        "\n",
        "## Third, the B1+ map is rescaled into nT/V\n",
        "\n",
        "## Fourth, the warped mask if used to extract the B1+ efficiency along the spinal cord\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d449d42",
      "metadata": {
        "id": "9d449d42"
      },
      "outputs": [],
      "source": [
        "# Step 1: Setting all the user-defined variables\n",
        "\n",
        "Target_FA=90 # change this to 80 for MAGNETOM scans!\n",
        "#root_dir='/Users/danielpapp/DATA/Traveling_Spines'\n",
        "#site_name='MGH'\n",
        "#subject_name='SubD'\n",
        "scan_name_TFL_B1_C3C4='TFL_B1_C3C4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad863694",
      "metadata": {
        "id": "ad863694"
      },
      "outputs": [],
      "source": [
        "# Step 2: select the anatmical and B1+ map\n",
        "\n",
        "TFL_C3C4_PATH = find_scan_dir(root_dir,site_name,subject_name,scan_name_TFL_B1_C3C4)\n",
        "TFL_C3C4_anatfile = find_matching_nii_json_pairs(TFL_C3C4_PATH, 'anatomical', 'ImageComments')[0]\n",
        "TFL_C3C4_B1mapfile = find_matching_nii_json_pairs(TFL_C3C4_PATH, 'angle map', 'ImageComments')[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "655b3838",
      "metadata": {
        "id": "655b3838"
      },
      "outputs": [],
      "source": [
        "# Step 3: Predefine filenames and paths for PROCESSING\n",
        "TFL_B1_C3C4_PROCESSING_PATH=os.path.join(root_dir,'Processing',site_name,subject_name,scan_name_TFL_B1_C3C4)\n",
        "if not os.path.isdir(TFL_B1_C3C4_PROCESSING_PATH):\n",
        "    os.makedirs(TFL_B1_C3C4_PROCESSING_PATH)\n",
        "\n",
        "QCfilepath=os.path.join(TFL_B1_C3C4_PROCESSING_PATH,'qc')\n",
        "TFL_B1_C3C4_warp_2_MP2RAGEfilename=os.path.join(TFL_B1_C3C4_PROCESSING_PATH,TFL_C3C4_anatfile.split('.')[0].split('/')[-1]+'_warp_2_MP2RAGE.nii.gz')\n",
        "warpMP2RAGE_2_TFLB1filename=os.path.join(TFL_B1_C3C4_PROCESSING_PATH,TFL_C3C4_anatfile.split('.')[0].split('/')[-1]+'_warp_MP2RAGE_2_B1.nii.gz')\n",
        "warpedmaskname=os.path.join(TFL_B1_C3C4_PROCESSING_PATH,TFL_C3C4_anatfile.split('.')[0].split('/')[-1]+'_MP2RAGE_mask_warped.nii.gz')\n",
        "TFL_C3C4_B1mapfile_nTpV=os.path.join(TFL_B1_C3C4_PROCESSING_PATH,TFL_C3C4_B1mapfile.split('.')[0].split('/')[-1]+'_nTpV.nii.gz')\n",
        "TFL_C3C4_B1mapfile_CSV=os.path.join(TFL_B1_C3C4_PROCESSING_PATH,TFL_C3C4_B1mapfile.split('.')[0].split('/')[-1]+'_nTpV.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TFL_B1_C3C4_warp_2_MP2RAGEfilename)\n",
        "print(warpMP2RAGE_2_TFLB1filename)"
      ],
      "metadata": {
        "id": "KiiycBuvML17"
      },
      "id": "KiiycBuvML17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96c6a39",
      "metadata": {
        "id": "d96c6a39"
      },
      "outputs": [],
      "source": [
        "# Step 4: Coregistering the anatomical of the B1 scan to the MP2RAGE scan and warping the mask\n",
        "\n",
        "# First, lets make sure that the results from the MP2RAGE processing exist\n",
        "[MP2RAGE_UNI_filename,MP2RAGE_UNI_maskfilename]=MP2RAGE_checker(root_dir,site_name,subject_name,scan_name_TFL_B1_C3C4)\n",
        "\n",
        "# Then, lets coregister the scans\n",
        "#run_subprocess(f\"sct_register_multimodal -i {TFL_C3C4_anatfile} -d {MP2RAGE_UNI_filename} -ofolder {TFL_B1_C3C4_PROCESSING_PATH} -owarp {TFL_B1_C3C4_warp_2_MP2RAGEfilename} -owarpinv {warpMP2RAGE_2_TFLB1filename} -qc {QCfilepath}\")\n",
        "run_subprocess(f\"sct_register_multimodal -d {TFL_C3C4_anatfile} -i {MP2RAGE_UNI_filename} -ofolder {TFL_B1_C3C4_PROCESSING_PATH} -owarp {warpMP2RAGE_2_TFLB1filename} -qc {QCfilepath}\")\n",
        "\n",
        "# Apply the warp to the mask\n",
        "run_subprocess(f\"sct_apply_transfo -i {MP2RAGE_UNI_maskfilename} -d {TFL_C3C4_anatfile} -w {warpMP2RAGE_2_TFLB1filename} -o {warpedmaskname} -x nn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e00f801",
      "metadata": {
        "id": "5e00f801"
      },
      "outputs": [],
      "source": [
        "# Step 5: Converting the B1+ map for flip angle to nT/V and then extracting the value along the spinal cord\n",
        "\n",
        "# finding the reference voltage\n",
        "TFL_B1_C3C4_jsonfile = TFL_C3C4_B1mapfile.replace(\".nii.gz\", \".json\")\n",
        "RefVol_C3C4 = extract_tx_ref_amp(TFL_B1_C3C4_jsonfile)\n",
        "\n",
        "# Maths for Kyle Gilbert\n",
        "#GAMMA = 2.675e8\n",
        "#VoltageAtSocket = RefVol_C3C4 * 10**-0.095\n",
        "#B1eff_mag = (AcquiredFA ./ RequestedFA) .* (pi ./ (GAMMA .* 1e-3 .* VoltageAtSocket)); % [T/V]\n",
        "#B1eff_mag = B1eff_mag .* 1e9; % [T/V] to [nT/V]\n",
        "# The costants sum up to 130.492, so to convert the B1map to nT/V, it has to be divided by 10 (to get it back into units of FA)\n",
        "# then multiplied by 130.492 and divided by the VoltageAtSocket\n",
        "VoltageAtSocket = RefVol_C3C4 * 10**-0.095\n",
        "\n",
        "# sct_maths did something funky with one of the divisions, switching to niimath for now\n",
        "run_subprocess(f\"niimath {TFL_C3C4_B1mapfile} -div 10 -mul 130.492 -div {VoltageAtSocket} {TFL_C3C4_B1mapfile_nTpV}\")\n",
        "\n",
        "# Finally, we can use the warped mask to extract the B1+ efficiency along the SC\n",
        "run_subprocess(f\"sct_extract_metric -i {TFL_C3C4_B1mapfile_nTpV} -f {warpedmaskname} -perslice 1 -o {TFL_C3C4_B1mapfile_CSV}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef9e42f",
      "metadata": {
        "scrolled": true,
        "id": "eef9e42f"
      },
      "outputs": [],
      "source": [
        "# Step 6: Visual QA for the coregisration of the mask and plotting the B1+ efficiency\n",
        "# Shamelssly stolen from\n",
        "# https://colab.research.google.com/github/evaalonsoortiz/7t-spine-coil/blob/main/7t_spine_coil_demo.ipynb\n",
        "\n",
        "tfl_b1_anat = nib.load(TFL_C3C4_anatfile)\n",
        "warped_mask = nib.load(warpedmaskname)\n",
        "img_data = tfl_b1_anat.get_fdata()\n",
        "seg_data = warped_mask.get_fdata()\n",
        "seg_data = np.ma.masked_where(seg_data < 0.3, seg_data)\n",
        "\n",
        "# Overlay the two images\n",
        "fig, ax = plt.subplots()\n",
        "plt.axis('off')\n",
        "img1 = ax.imshow(np.rot90(img_data[:,:,28]/10), cmap=plt.cm.gray)\n",
        "ax.imshow(np.rot90(seg_data[:,:,28]), cmap=plt.cm.autumn, interpolation='none', alpha=0.5)\n",
        "plt.colorbar(img1)\n",
        "img1.set_clim(vmin=0, vmax=90)\n",
        "plt.title('QA overlay for the anatomical of the B1 map and the warped mask')\n",
        "plt.show()\n",
        "\n",
        "TFL_B1_nTpV_along_cord=signal_extractor_from_csv(TFL_C3C4_B1mapfile_CSV)\n",
        "TFL_B1_nTpV_along_cord = TFL_B1_nTpV_along_cord[~np.isnan(TFL_B1_nTpV_along_cord)] #remove NANs\n",
        "plt.plot(TFL_B1_nTpV_along_cord)\n",
        "TFL_B1_nTpV_along_cord_mean=np.round(np.mean(TFL_B1_nTpV_along_cord))\n",
        "titlestring= f\"B1+ efficiency [nT/V] along the cord in the warped mask. Mean value: {TFL_B1_nTpV_along_cord_mean}\"\n",
        "plt.title(titlestring)\n",
        "plt.xlabel('Slice along the I-->S direction')\n",
        "plt.ylabel('nT/V')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eac17b64",
      "metadata": {
        "id": "eac17b64"
      },
      "source": [
        "# DREAM_B1map processing: LARGE FOV\n",
        "\n",
        "## Here, the following steps are carried out:\n",
        "\n",
        "## First, the anatomical and B1+ maps of the LARGE FOV DREAM scan acquired with Optimal Reference Voltage are identified\n",
        "\n",
        "## Second, the anatomical is coregistered to the MP2RAGE scan, and the mask derived from the MP2RAGE scan is warped to the space of the B1+ map\n",
        "\n",
        "## Third, the B1+ map is rescaled into nT/V\n",
        "\n",
        "## Fourth, the warped mask if used to extract the B1+ efficiency along the spinal cord\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01912532",
      "metadata": {
        "id": "01912532"
      },
      "outputs": [],
      "source": [
        "# Step 1: Setting all the user-defined variables\n",
        "#root_dir='/Users/danielpapp/DATA/Traveling_Spines'\n",
        "#site_name='MGH'\n",
        "#subject_name='SubD'\n",
        "scan_name_DREAM_LARGE='DREAM_LARGE'\n",
        "\n",
        "\n",
        "# Step 2: select the anatmical and B1+ map\n",
        "DREAM_LARGE_PATH = find_scan_dir(root_dir,site_name,subject_name,scan_name_DREAM_LARGE)\n",
        "DREAM_LARGE_anatfile = find_matching_nii_json_pairs(DREAM_LARGE_PATH, 'FID', 'ImageComments')[-1] #this will be the distortion corrrected anatomical\n",
        "DREAM_LARGE_B1mapfile = find_matching_nii_json_pairs(DREAM_LARGE_PATH, 'Flipangle Map', 'ImageComments')[-1] # this will be the distortion corrected map\n",
        "\n",
        "\n",
        "# Step 3: Predefine filenames and paths for PROCESSING\n",
        "DREAM_LARGE_PROCESSING_PATH=os.path.join(root_dir,'Processing',site_name,subject_name,scan_name_DREAM_LARGE)\n",
        "if not os.path.isdir(DREAM_LARGE_PROCESSING_PATH):\n",
        "    os.makedirs(DREAM_LARGE_PROCESSING_PATH)\n",
        "\n",
        "QCfilepath_DREAM_LARGE=os.path.join(DREAM_LARGE_PROCESSING_PATH,'qc')\n",
        "DREAM_LARGE_warp_2_MP2RAGEfilename=os.path.join(DREAM_LARGE_PROCESSING_PATH,DREAM_LARGE_anatfile.split('.')[0].split('/')[-1]+'_warp_2_MP2RAGE.nii.gz')\n",
        "warpMP2RAGE_2_DREAM_LARGEfilename=os.path.join(DREAM_LARGE_PROCESSING_PATH,DREAM_LARGE_anatfile.split('.')[0].split('/')[-1]+'_warp_MP2RAGE_2_DREAM.nii.gz')\n",
        "warpedmaskname_DREAM_LARGE=os.path.join(DREAM_LARGE_PROCESSING_PATH,DREAM_LARGE_anatfile.split('.')[0].split('/')[-1]+'_MP2RAGE_mask_warped.nii.gz')\n",
        "DREAM_LARGE_B1mapfile_nTpV=os.path.join(DREAM_LARGE_PROCESSING_PATH,DREAM_LARGE_anatfile.split('.')[0].split('/')[-1]+'_nTpV.nii.gz')\n",
        "DREAM_LARGE_B1mapfile_CVS=os.path.join(DREAM_LARGE_PROCESSING_PATH,DREAM_LARGE_anatfile.split('.')[0].split('/')[-1]+'_nTpV.csv')\n",
        "\n",
        "# Step 4: Coregistering the anatomical of the B1 scan to the MP2RAGE scan and warping the mask\n",
        "\n",
        "# First, lets make sure that the results from the MP2RAGE processing exist\n",
        "[MP2RAGE_UNI_filename,MP2RAGE_UNI_maskfilename]=MP2RAGE_checker(root_dir,site_name,subject_name,scan_name_DREAM_LARGE)\n",
        "\n",
        "# Then, lets coregister the scans\n",
        "#run_subprocess(f\"sct_register_multimodal -i {DREAM_LARGE_anatfile} -d {MP2RAGE_UNI_filename} -ofolder {DREAM_LARGE_PROCESSING_PATH} -owarp {DREAM_LARGE_warp_2_MP2RAGEfilename} -owarpinv {warpMP2RAGE_2_DREAM_LARGEfilename} -qc {QCfilepath_DREAM_LARGE}\")\n",
        "run_subprocess(f\"sct_register_multimodal -d {DREAM_LARGE_anatfile} -i {MP2RAGE_UNI_filename} -ofolder {DREAM_LARGE_PROCESSING_PATH} -owarp {warpMP2RAGE_2_DREAM_LARGEfilename} -qc {QCfilepath_DREAM_LARGE}\")\n",
        "\n",
        "# Apply the warp to the mask\n",
        "run_subprocess(f\"sct_apply_transfo -i {MP2RAGE_UNI_maskfilename} -d {DREAM_LARGE_anatfile} -w {warpMP2RAGE_2_DREAM_LARGEfilename} -o {warpedmaskname_DREAM_LARGE} -x nn\")\n",
        "\n",
        "# Step 5: Converting the B1+ map for flip angle to nT/V and then extracting the value along the spinal cord\n",
        "\n",
        "# finding the reference voltage\n",
        "DREAM_LARGE_jsonfile = DREAM_LARGE_B1mapfile.replace(\".nii.gz\", \".json\")\n",
        "RefVol_DREAM_LARGE = extract_tx_ref_amp(DREAM_LARGE_jsonfile)\n",
        "# We also need the flip angle here, as this might have been modified by users\n",
        "FA_DREAM_LARGE = extract_FA(DREAM_LARGE_jsonfile)\n",
        "\n",
        "# Maths for Kyle Gilbert\n",
        "GAMMA = 2.675e8\n",
        "VoltageAtSocket = RefVol_DREAM_LARGE * 10**-0.095\n",
        "B1_nTpV_multiplier_DREAM_LARGE = (1 / FA_DREAM_LARGE) * (np.pi*1e9 / (GAMMA * 1e-3 * VoltageAtSocket)) /10\n",
        "run_subprocess(f\"niimath {DREAM_LARGE_B1mapfile} -mul {B1_nTpV_multiplier_DREAM_LARGE} {DREAM_LARGE_B1mapfile_nTpV}\")\n",
        "\n",
        "# Finally, we can use the warped mask to extract the B1+ efficiency along the SC\n",
        "run_subprocess(f\"sct_extract_metric -i {DREAM_LARGE_B1mapfile_nTpV} -f {warpedmaskname_DREAM_LARGE} -perslice 1 -o {DREAM_LARGE_B1mapfile_CVS}\")\n",
        "\n",
        "# Step 6: Visual QA for the coregisration of the mask and plotting the B1+ efficiency\n",
        "# Shamelssly stolen from\n",
        "# https://colab.research.google.com/github/evaalonsoortiz/7t-spine-coil/blob/main/7t_spine_coil_demo.ipynb\n",
        "\n",
        "DREAM_LARGE_anat = nib.load(DREAM_LARGE_anatfile)\n",
        "warped_mask_DREAM_LARGE = nib.load(warpedmaskname_DREAM_LARGE)\n",
        "img_data = DREAM_LARGE_anat.get_fdata()\n",
        "seg_data = warped_mask_DREAM_LARGE.get_fdata()\n",
        "seg_data = np.ma.masked_where(seg_data < 0.3, seg_data)\n",
        "\n",
        "# Overlay the two images\n",
        "fig, ax = plt.subplots()\n",
        "plt.axis('off')\n",
        "\n",
        "img1 = ax.imshow(np.rot90(img_data[:,:,int(np.round(img_data.shape[-1]/2))]/10), cmap=plt.cm.gray)\n",
        "ax.imshow(np.rot90(seg_data[:,:,int(np.round(img_data.shape[-1]/2))]), cmap=plt.cm.autumn, interpolation='none', alpha=0.5)\n",
        "plt.colorbar(img1)\n",
        "img1.set_clim(vmin=0, vmax=90)\n",
        "plt.title('QA overlay for the anatomical of the DREAM LARGE FOV B1 map and the warped mask')\n",
        "plt.show()\n",
        "\n",
        "DREAM_LARGE_nTpV_along_cord=signal_extractor_from_csv(DREAM_LARGE_B1mapfile_CVS)\n",
        "DREAM_LARGE_nTpV_along_cord = DREAM_LARGE_nTpV_along_cord[~np.isnan(DREAM_LARGE_nTpV_along_cord)] #remove NANs\n",
        "plt.plot(DREAM_LARGE_nTpV_along_cord)\n",
        "DREAM_LARGE_nTpV_along_cord_mean=np.round(np.mean(DREAM_LARGE_nTpV_along_cord))\n",
        "titlestring= f\"B1+ efficiency [nT/V] along the cord in the warped mask. Mean value: {DREAM_LARGE_nTpV_along_cord_mean}\"\n",
        "plt.title(titlestring)\n",
        "plt.xlabel('Slice along the I-->S direction')\n",
        "plt.ylabel('nT/V')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f903709a",
      "metadata": {
        "id": "f903709a"
      },
      "source": [
        "# DREAM_B1map processing: MEDIUM FOV\n",
        "\n",
        "## Here, the following steps are carried out:\n",
        "\n",
        "## First, the anatomical and B1+ maps of the MEDIUM FOV DREAM scan acquired with Optimal Reference Voltage are identified\n",
        "\n",
        "## Second, the anatomical is coregistered to the MP2RAGE scan, and the mask derived from the MP2RAGE scan is warped to the space of the B1+ map\n",
        "\n",
        "## Third, the B1+ map is rescaled into nT/V\n",
        "\n",
        "## Fourth, the warped mask if used to extract the B1+ efficiency along the spinal cord\n",
        "\n",
        "## Fifth, this process is repeated for the Medium FOV DREAM scans acquired with 2/3rd and 150% of the Optimal Reference Voltage (or 2/3rds and hardware maximum, whichever is available)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "621d4320",
      "metadata": {
        "id": "621d4320"
      },
      "source": [
        "### Optimal Reference Voltage MEDIUM FOV DREAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5368fa5c",
      "metadata": {
        "id": "5368fa5c"
      },
      "outputs": [],
      "source": [
        "## Optimal Reference Voltage DREAM\n",
        "# Step 1: Setting all the user-defined variables\n",
        "#root_dir='/Users/danielpapp/DATA/Traveling_Spines'\n",
        "#site_name='MGH'\n",
        "#subject_name='SubD'\n",
        "scan_name_DREAM_MEDIUM='DREAM_MEDIUM'\n",
        "\n",
        "# Step 2: select the anatmical and B1+ map\n",
        "DREAM_MEDIUM_PATH = find_scan_dir(root_dir,site_name,subject_name,scan_name_DREAM_MEDIUM)\n",
        "DREAM_MEDIUM_anatfile = find_matching_nii_json_pairs(DREAM_MEDIUM_PATH, 'FID', 'ImageComments')[-1] #this will be the distortion corrrected anatomical\n",
        "DREAM_MEDIUM_B1mapfile = find_matching_nii_json_pairs(DREAM_MEDIUM_PATH, 'Flipangle Map', 'ImageComments')[-1] # this will be the distortion corrected map\n",
        "\n",
        "# Step 3: Predefine filenames and paths for PROCESSING\n",
        "DREAM_MEDIUM_PROCESSING_PATH=os.path.join(root_dir,'Processing',site_name,subject_name,scan_name_DREAM_MEDIUM)\n",
        "if not os.path.isdir(DREAM_MEDIUM_PROCESSING_PATH):\n",
        "    os.makedirs(DREAM_MEDIUM_PROCESSING_PATH)\n",
        "\n",
        "QCfilepath_DREAM_MEDIUM=os.path.join(DREAM_MEDIUM_PROCESSING_PATH,'qc')\n",
        "DREAM_MEDIUM_warp_2_MP2RAGEfilename=os.path.join(DREAM_MEDIUM_PROCESSING_PATH,DREAM_MEDIUM_anatfile.split('.')[0].split('/')[-1]+'_warp_2_MP2RAGE.nii.gz')\n",
        "warpMP2RAGE_2_DREAM_MEDIUMfilename=os.path.join(DREAM_MEDIUM_PROCESSING_PATH,DREAM_MEDIUM_anatfile.split('.')[0].split('/')[-1]+'_warp_MP2RAGE_2_DREAM.nii.gz')\n",
        "warpedmaskname_DREAM_MEDIUM=os.path.join(DREAM_MEDIUM_PROCESSING_PATH,DREAM_MEDIUM_anatfile.split('.')[0].split('/')[-1]+'_MP2RAGE_mask_warped.nii.gz')\n",
        "DREAM_MEDIUM_B1mapfile_nTpV=os.path.join(DREAM_MEDIUM_PROCESSING_PATH,DREAM_MEDIUM_anatfile.split('.')[0].split('/')[-1]+'_nTpV.nii.gz')\n",
        "DREAM_MEDIUM_B1mapfile_CVS=os.path.join(DREAM_MEDIUM_PROCESSING_PATH,DREAM_MEDIUM_anatfile.split('.')[0].split('/')[-1]+'_nTpV.csv')\n",
        "\n",
        "# Step 4: Coregistering the anatomical of the B1 scan to the MP2RAGE scan and warping the mask\n",
        "\n",
        "# First, lets make sure that the results from the MP2RAGE processing exist\n",
        "[MP2RAGE_UNI_filename,MP2RAGE_UNI_maskfilename]=MP2RAGE_checker(root_dir,site_name,subject_name,scan_name_DREAM_MEDIUM)\n",
        "\n",
        "# Then, lets coregister the scans\n",
        "#run_subprocess(f\"sct_register_multimodal -i {DREAM_MEDIUM_anatfile} -d {MP2RAGE_UNI_filename} -ofolder {DREAM_MEDIUM_PROCESSING_PATH} -owarp {DREAM_MEDIUM_warp_2_MP2RAGEfilename} -owarpinv {warpMP2RAGE_2_DREAM_MEDIUMfilename} -qc {QCfilepath_DREAM_MEDIUM}\")\n",
        "run_subprocess(f\"sct_register_multimodal -d {DREAM_MEDIUM_anatfile} -i {MP2RAGE_UNI_filename} -ofolder {DREAM_MEDIUM_PROCESSING_PATH} -owarp {warpMP2RAGE_2_DREAM_MEDIUMfilename} -qc {QCfilepath_DREAM_MEDIUM}\")\n",
        "\n",
        "# Apply the warp to the mask\n",
        "run_subprocess(f\"sct_apply_transfo -i {MP2RAGE_UNI_maskfilename} -d {DREAM_MEDIUM_anatfile} -w {warpMP2RAGE_2_DREAM_MEDIUMfilename} -o {warpedmaskname_DREAM_MEDIUM} -x nn\")\n",
        "\n",
        "# Step 5: Converting the B1+ map for flip angle to nT/V and then extracting the value along the spinal cord\n",
        "\n",
        "# finding the reference voltage\n",
        "DREAM_MEDIUM_jsonfile = DREAM_MEDIUM_B1mapfile.replace(\".nii.gz\", \".json\")\n",
        "RefVol_DREAM_MEDIUM = extract_tx_ref_amp(DREAM_MEDIUM_jsonfile)\n",
        "# We also need the flip angle here, as this might have been modified by users\n",
        "FA_DREAM_MEDIUM = extract_FA(DREAM_MEDIUM_jsonfile)\n",
        "\n",
        "# Maths for Kyle Gilbert\n",
        "GAMMA = 2.675e8\n",
        "VoltageAtSocket = RefVol_DREAM_MEDIUM * 10**-0.095\n",
        "B1_nTpV_multiplier_DREAM_MEDIUM = (1 / FA_DREAM_MEDIUM) * (np.pi*1e9 / (GAMMA * 1e-3 * VoltageAtSocket)) /10\n",
        "run_subprocess(f\"niimath {DREAM_MEDIUM_B1mapfile} -mul {B1_nTpV_multiplier_DREAM_MEDIUM} {DREAM_MEDIUM_B1mapfile_nTpV}\")\n",
        "\n",
        "# Finally, we can use the warped mask to extract the B1+ efficiency along the SC\n",
        "run_subprocess(f\"sct_extract_metric -i {DREAM_MEDIUM_B1mapfile_nTpV} -f {warpedmaskname_DREAM_MEDIUM} -perslice 1 -o {DREAM_MEDIUM_B1mapfile_CVS}\")\n",
        "\n",
        "# Step 6: Visual QA for the coregisration of the mask and plotting the B1+ efficiency\n",
        "# Shamelssly stolen from\n",
        "# https://colab.research.google.com/github/evaalonsoortiz/7t-spine-coil/blob/main/7t_spine_coil_demo.ipynb\n",
        "\n",
        "DREAM_MEDIUM_anat = nib.load(DREAM_MEDIUM_anatfile)\n",
        "warped_mask_DREAM_MEDIUM = nib.load(warpedmaskname_DREAM_MEDIUM)\n",
        "img_data = DREAM_MEDIUM_anat.get_fdata()\n",
        "seg_data = warped_mask_DREAM_MEDIUM.get_fdata()\n",
        "seg_data = np.ma.masked_where(seg_data < 0.3, seg_data)\n",
        "\n",
        "# Overlay the two images\n",
        "fig, ax = plt.subplots()\n",
        "plt.axis('off')\n",
        "\n",
        "img1 = ax.imshow(np.rot90(img_data[:,:,int(np.round(img_data.shape[-1]/2))]/10), cmap=plt.cm.gray)\n",
        "ax.imshow(np.rot90(seg_data[:,:,int(np.round(img_data.shape[-1]/2))]), cmap=plt.cm.autumn, interpolation='none', alpha=0.5)\n",
        "plt.colorbar(img1)\n",
        "img1.set_clim(vmin=0, vmax=90)\n",
        "plt.title('QA overlay for the anatomical of the DREAM MEDIUM FOV B1 map and the warped mask')\n",
        "plt.show()\n",
        "\n",
        "DREAM_MEDIUM_nTpV_along_cord=signal_extractor_from_csv(DREAM_MEDIUM_B1mapfile_CVS)\n",
        "DREAM_MEDIUM_nTpV_along_cord = DREAM_MEDIUM_nTpV_along_cord[~np.isnan(DREAM_MEDIUM_nTpV_along_cord)] #remove NANs\n",
        "plt.plot(DREAM_MEDIUM_nTpV_along_cord)\n",
        "DREAM_MEDIUM_nTpV_along_cord_mean=np.round(np.mean(DREAM_MEDIUM_nTpV_along_cord))\n",
        "titlestring= f\"B1+ efficiency [nT/V] along the cord in the warped mask. Mean value: {DREAM_MEDIUM_nTpV_along_cord_mean}\"\n",
        "plt.title(titlestring)\n",
        "plt.xlabel('Slice along the I-->S direction')\n",
        "plt.ylabel('nT/V')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab9c1cdf",
      "metadata": {
        "id": "ab9c1cdf"
      },
      "source": [
        "### 2/3rds of Optimal Reference Voltage MEDIUM FOV DREAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "988d1878",
      "metadata": {
        "id": "988d1878"
      },
      "outputs": [],
      "source": [
        "## 2/3rds of Optimal Reference Voltage DREAM\n",
        "# Step 1: Setting all the user-defined variables\n",
        "#root_dir='/Users/danielpapp/DATA/Traveling_Spines'\n",
        "#site_name='MGH'\n",
        "#subject_name='SubD'\n",
        "scan_name_DREAM_MEDIUM_066='DREAM_MEDIUM_066'\n",
        "\n",
        "# Step 2: select the anatmical and B1+ map\n",
        "DREAM_MEDIUM_PATH_066 = find_scan_dir(root_dir,site_name,subject_name,scan_name_DREAM_MEDIUM_066)\n",
        "DREAM_MEDIUM_anatfile_066 = find_matching_nii_json_pairs(DREAM_MEDIUM_PATH_066, 'FID', 'ImageComments')[-1] #this will be the distortion corrrected anatomical\n",
        "DREAM_MEDIUM_B1mapfile_066 = find_matching_nii_json_pairs(DREAM_MEDIUM_PATH_066, 'Flipangle Map', 'ImageComments')[-1] # this will be the distortion corrected map\n",
        "\n",
        "# Step 3: Predefine filenames and paths for PROCESSING\n",
        "DREAM_MEDIUM_PROCESSING_PATH_066=os.path.join(root_dir,'Processing',site_name,subject_name,scan_name_DREAM_MEDIUM_066)\n",
        "if not os.path.isdir(DREAM_MEDIUM_PROCESSING_PATH_066):\n",
        "    os.makedirs(DREAM_MEDIUM_PROCESSING_PATH_066)\n",
        "\n",
        "QCfilepath_DREAM_MEDIUM_066=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_066,'qc')\n",
        "DREAM_MEDIUM_warp_2_MP2RAGEfilename_066=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_066,DREAM_MEDIUM_anatfile_066.split('.')[0].split('/')[-1]+'_warp_2_MP2RAGE.nii.gz')\n",
        "warpMP2RAGE_2_DREAM_MEDIUMfilename_066=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_066,DREAM_MEDIUM_anatfile_066.split('.')[0].split('/')[-1]+'_warp_MP2RAGE_2_DREAM.nii.gz')\n",
        "warpedmaskname_DREAM_MEDIUM_066=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_066,DREAM_MEDIUM_anatfile_066.split('.')[0].split('/')[-1]+'_MP2RAGE_mask_warped.nii.gz')\n",
        "DREAM_MEDIUM_B1mapfile_nTpV_066=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_066,DREAM_MEDIUM_anatfile_066.split('.')[0].split('/')[-1]+'_nTpV.nii.gz')\n",
        "DREAM_MEDIUM_B1mapfile_CVS_066=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_066,DREAM_MEDIUM_anatfile_066.split('.')[0].split('/')[-1]+'_nTpV.csv')\n",
        "\n",
        "# Step 4: Coregistering the anatomical of the B1 scan to the MP2RAGE scan and warping the mask\n",
        "\n",
        "# First, lets make sure that the results from the MP2RAGE processing exist\n",
        "[MP2RAGE_UNI_filename,MP2RAGE_UNI_maskfilename]=MP2RAGE_checker(root_dir,site_name,subject_name,scan_name_DREAM_MEDIUM_066)\n",
        "\n",
        "# Then, lets coregister the scans\n",
        "#run_subprocess(f\"sct_register_multimodal -i {DREAM_MEDIUM_anatfile_066} -d {MP2RAGE_UNI_filename} -ofolder {DREAM_MEDIUM_PROCESSING_PATH_066} -owarp {DREAM_MEDIUM_warp_2_MP2RAGEfilename_066} -owarpinv {warpMP2RAGE_2_DREAM_MEDIUMfilename_066} -qc {QCfilepath_DREAM_MEDIUM_066}\")\n",
        "run_subprocess(f\"sct_register_multimodal -d {DREAM_MEDIUM_anatfile_066} -i {MP2RAGE_UNI_filename} -ofolder {DREAM_MEDIUM_PROCESSING_PATH_066} -owarp {warpMP2RAGE_2_DREAM_MEDIUMfilename_066} -qc {QCfilepath_DREAM_MEDIUM_066}\")\n",
        "\n",
        "# Apply the warp to the mask\n",
        "run_subprocess(f\"sct_apply_transfo -i {MP2RAGE_UNI_maskfilename} -d {DREAM_MEDIUM_anatfile_066} -w {warpMP2RAGE_2_DREAM_MEDIUMfilename_066} -o {warpedmaskname_DREAM_MEDIUM_066} -x nn\")\n",
        "\n",
        "# Step 5: Converting the B1+ map for flip angle to nT/V and then extracting the value along the spinal cord\n",
        "\n",
        "# finding the reference voltage\n",
        "DREAM_MEDIUM_jsonfile_066 = DREAM_MEDIUM_B1mapfile_066.replace(\".nii.gz\", \".json\")\n",
        "RefVol_DREAM_MEDIUM_066 = extract_tx_ref_amp(DREAM_MEDIUM_jsonfile_066)\n",
        "# We also need the flip angle here, as this might have been modified by users\n",
        "FA_DREAM_MEDIUM_066 = extract_FA(DREAM_MEDIUM_jsonfile_066)\n",
        "\n",
        "# Maths for Kyle Gilbert\n",
        "GAMMA = 2.675e8\n",
        "VoltageAtSocket_066 = RefVol_DREAM_MEDIUM_066 * 10**-0.095\n",
        "B1_nTpV_multiplier_DREAM_MEDIUM_066 = (1 / FA_DREAM_MEDIUM_066) * (np.pi*1e9 / (GAMMA * 1e-3 * VoltageAtSocket_066)) /10\n",
        "run_subprocess(f\"niimath {DREAM_MEDIUM_B1mapfile_066} -mul {B1_nTpV_multiplier_DREAM_MEDIUM_066} {DREAM_MEDIUM_B1mapfile_nTpV_066}\")\n",
        "\n",
        "# Finally, we can use the warped mask to extract the B1+ efficiency along the SC\n",
        "run_subprocess(f\"sct_extract_metric -i {DREAM_MEDIUM_B1mapfile_nTpV_066} -f {warpedmaskname_DREAM_MEDIUM_066} -perslice 1 -o {DREAM_MEDIUM_B1mapfile_CVS_066}\")\n",
        "\n",
        "# Step 6: Visual QA for the coregisration of the mask and plotting the B1+ efficiency\n",
        "# Shamelssly stolen from\n",
        "# https://colab.research.google.com/github/evaalonsoortiz/7t-spine-coil/blob/main/7t_spine_coil_demo.ipynb\n",
        "\n",
        "DREAM_MEDIUM_anat_066 = nib.load(DREAM_MEDIUM_anatfile_066)\n",
        "warped_mask_DREAM_MEDIUM_066 = nib.load(warpedmaskname_DREAM_MEDIUM_066)\n",
        "img_data = DREAM_MEDIUM_anat_066.get_fdata()\n",
        "seg_data = warped_mask_DREAM_MEDIUM_066.get_fdata()\n",
        "seg_data = np.ma.masked_where(seg_data < 0.3, seg_data)\n",
        "\n",
        "# Overlay the two images\n",
        "fig, ax = plt.subplots()\n",
        "plt.axis('off')\n",
        "\n",
        "img1 = ax.imshow(np.rot90(img_data[:,:,int(np.round(img_data.shape[-1]/2))]/10), cmap=plt.cm.gray)\n",
        "ax.imshow(np.rot90(seg_data[:,:,int(np.round(img_data.shape[-1]/2))]), cmap=plt.cm.autumn, interpolation='none', alpha=0.5)\n",
        "plt.colorbar(img1)\n",
        "img1.set_clim(vmin=0, vmax=90)\n",
        "plt.title('QA overlay for the anatomical of the DREAM MEDIUM 066 FOV B1 map and the warped mask')\n",
        "plt.show()\n",
        "\n",
        "DREAM_MEDIUM_066_nTpV_along_cord=signal_extractor_from_csv(DREAM_MEDIUM_B1mapfile_CVS_066)\n",
        "DREAM_MEDIUM_066_nTpV_along_cord = DREAM_MEDIUM_066_nTpV_along_cord[~np.isnan(DREAM_MEDIUM_066_nTpV_along_cord)] #remove NANs\n",
        "plt.plot(DREAM_MEDIUM_066_nTpV_along_cord)\n",
        "DREAM_MEDIUM_066_nTpV_along_cord_mean=np.round(np.mean(DREAM_MEDIUM_066_nTpV_along_cord))\n",
        "titlestring= f\"B1+ efficiency [nT/V] along the cord in the warped mask. Mean value: {DREAM_MEDIUM_066_nTpV_along_cord_mean}\"\n",
        "plt.title(titlestring)\n",
        "plt.xlabel('Slice along the I-->S direction')\n",
        "plt.ylabel('nT/V')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7461741f",
      "metadata": {
        "id": "7461741f"
      },
      "source": [
        "### 150% or Hardware Limit of Optimal Reference Voltage MEDIUM FOV DREAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a94fe6e",
      "metadata": {
        "id": "4a94fe6e"
      },
      "outputs": [],
      "source": [
        "## 150% of Optimal Reference Voltage DREAM, or HW limit\n",
        "# IT IS UP TO THE USER TO DEFINE IF IT IS A 150% SCAN OR A HW LIMIT SCAN!!!!!\n",
        "# Step 1: Setting all the user-defined variables\n",
        "#root_dir='/Users/danielpapp/DATA/Traveling_Spines'\n",
        "#site_name='MGH'\n",
        "#subject_name='SubD'\n",
        "scan_name_DREAM_MEDIUM_HWLIMIT='DREAM_MEDIUM_HWLIMIT'\n",
        "\n",
        "# Step 2: select the anatmical and B1+ map\n",
        "DREAM_MEDIUM_PATH_HWLIMIT = find_scan_dir(root_dir,site_name,subject_name,scan_name_DREAM_MEDIUM_HWLIMIT)\n",
        "DREAM_MEDIUM_anatfile_HWLIMIT = find_matching_nii_json_pairs(DREAM_MEDIUM_PATH_HWLIMIT, 'FID', 'ImageComments')[-1] #this will be the distortion corrrected anatomical\n",
        "DREAM_MEDIUM_B1mapfile_HWLIMIT = find_matching_nii_json_pairs(DREAM_MEDIUM_PATH_HWLIMIT, 'Flipangle Map', 'ImageComments')[-1] # this will be the distortion corrected map\n",
        "\n",
        "# Step 3: Predefine filenames and paths for PROCESSING\n",
        "DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT=os.path.join(root_dir,'Processing',site_name,subject_name,scan_name_DREAM_MEDIUM_HWLIMIT)\n",
        "if not os.path.isdir(DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT):\n",
        "    os.makedirs(DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT)\n",
        "\n",
        "QCfilepath_DREAM_MEDIUM_HWLIMIT=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT,'qc')\n",
        "DREAM_MEDIUM_warp_2_MP2RAGEfilename_HWLIMIT=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT,DREAM_MEDIUM_anatfile_HWLIMIT.split('.')[0].split('/')[-1]+'_warp_2_MP2RAGE.nii.gz')\n",
        "warpMP2RAGE_2_DREAM_MEDIUMfilename_HWLIMIT=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT,DREAM_MEDIUM_anatfile_HWLIMIT.split('.')[0].split('/')[-1]+'_warp_MP2RAGE_2_DREAM.nii.gz')\n",
        "warpedmaskname_DREAM_MEDIUM_HWLIMIT=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT,DREAM_MEDIUM_anatfile_HWLIMIT.split('.')[0].split('/')[-1]+'_MP2RAGE_mask_warped.nii.gz')\n",
        "DREAM_MEDIUM_B1mapfile_nTpV_HWLIMIT=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT,DREAM_MEDIUM_anatfile_HWLIMIT.split('.')[0].split('/')[-1]+'_nTpV.nii.gz')\n",
        "DREAM_MEDIUM_B1mapfile_CVS_HWLIMIT=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT,DREAM_MEDIUM_anatfile_HWLIMIT.split('.')[0].split('/')[-1]+'_nTpV.csv')\n",
        "\n",
        "# Step 4: Coregistering the anatomical of the B1 scan to the MP2RAGE scan and warping the mask\n",
        "\n",
        "# First, lets make sure that the results from the MP2RAGE processing exist\n",
        "[MP2RAGE_UNI_filename,MP2RAGE_UNI_maskfilename]=MP2RAGE_checker(root_dir,site_name,subject_name,scan_name_DREAM_MEDIUM_HWLIMIT)\n",
        "\n",
        "# Then, lets coregister the scans\n",
        "#run_subprocess(f\"sct_register_multimodal -i {DREAM_MEDIUM_anatfile_HWLIMIT} -d {MP2RAGE_UNI_filename} -ofolder {DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT} -owarp {DREAM_MEDIUM_warp_2_MP2RAGEfilename_HWLIMIT} -owarpinv {warpMP2RAGE_2_DREAM_MEDIUMfilename_HWLIMIT} -qc {QCfilepath_DREAM_MEDIUM_HWLIMIT}\")\n",
        "run_subprocess(f\"sct_register_multimodal -d {DREAM_MEDIUM_anatfile_HWLIMIT} -i {MP2RAGE_UNI_filename} -ofolder {DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT} -owarp {warpMP2RAGE_2_DREAM_MEDIUMfilename_HWLIMIT} -qc {QCfilepath_DREAM_MEDIUM_HWLIMIT}\")\n",
        "\n",
        "# Apply the warp to the mask\n",
        "run_subprocess(f\"sct_apply_transfo -i {MP2RAGE_UNI_maskfilename} -d {DREAM_MEDIUM_anatfile_HWLIMIT} -w {warpMP2RAGE_2_DREAM_MEDIUMfilename_HWLIMIT} -o {warpedmaskname_DREAM_MEDIUM_HWLIMIT} -x nn\")\n",
        "\n",
        "# Step 5: Converting the B1+ map for flip angle to nT/V and then extracting the value along the spinal cord\n",
        "\n",
        "# finding the reference voltage\n",
        "DREAM_MEDIUM_jsonfile_HWLIMIT = DREAM_MEDIUM_B1mapfile_HWLIMIT.replace(\".nii.gz\", \".json\")\n",
        "RefVol_DREAM_MEDIUM_HWLIMIT = extract_tx_ref_amp(DREAM_MEDIUM_jsonfile_HWLIMIT)\n",
        "# We also need the flip angle here, as this might have been modified by users\n",
        "FA_DREAM_MEDIUM_HWLIMIT = extract_FA(DREAM_MEDIUM_jsonfile_HWLIMIT)\n",
        "\n",
        "# Maths for Kyle Gilbert\n",
        "GAMMA = 2.675e8\n",
        "VoltageAtSocket_HWLIMIT = RefVol_DREAM_MEDIUM_HWLIMIT * 10**-0.095\n",
        "B1_nTpV_multiplier_DREAM_MEDIUM_HWLIMIT = (1 / FA_DREAM_MEDIUM_HWLIMIT) * (np.pi*1e9 / (GAMMA * 1e-3 * VoltageAtSocket_HWLIMIT)) /10\n",
        "run_subprocess(f\"niimath {DREAM_MEDIUM_B1mapfile_HWLIMIT} -mul {B1_nTpV_multiplier_DREAM_MEDIUM_HWLIMIT} {DREAM_MEDIUM_B1mapfile_nTpV_HWLIMIT}\")\n",
        "\n",
        "# Finally, we can use the warped mask to extract the B1+ efficiency along the SC\n",
        "run_subprocess(f\"sct_extract_metric -i {DREAM_MEDIUM_B1mapfile_nTpV_HWLIMIT} -f {warpedmaskname_DREAM_MEDIUM_HWLIMIT} -perslice 1 -o {DREAM_MEDIUM_B1mapfile_CVS_HWLIMIT}\")\n",
        "\n",
        "# Step 6: Visual QA for the coregisration of the mask and plotting the B1+ efficiency\n",
        "# Shamelssly stolen from\n",
        "# https://colab.research.google.com/github/evaalonsoortiz/7t-spine-coil/blob/main/7t_spine_coil_demo.ipynb\n",
        "\n",
        "DREAM_MEDIUM_anat_HWLIMIT = nib.load(DREAM_MEDIUM_anatfile_HWLIMIT)\n",
        "warped_mask_DREAM_MEDIUM_HWLIMIT = nib.load(warpedmaskname_DREAM_MEDIUM_HWLIMIT)\n",
        "img_data = DREAM_MEDIUM_anat_HWLIMIT.get_fdata()\n",
        "seg_data = warped_mask_DREAM_MEDIUM_HWLIMIT.get_fdata()\n",
        "seg_data = np.ma.masked_where(seg_data < 0.3, seg_data)\n",
        "\n",
        "# Overlay the two images\n",
        "fig, ax = plt.subplots()\n",
        "plt.axis('off')\n",
        "\n",
        "img1 = ax.imshow(np.rot90(img_data[:,:,int(np.round(img_data.shape[-1]/2))]/10), cmap=plt.cm.gray)\n",
        "ax.imshow(np.rot90(seg_data[:,:,int(np.round(img_data.shape[-1]/2))]), cmap=plt.cm.autumn, interpolation='none', alpha=0.5)\n",
        "plt.colorbar(img1)\n",
        "img1.set_clim(vmin=0, vmax=90)\n",
        "plt.title('QA overlay for the anatomical of the DREAM MEDIUM HWLIMIT FOV B1 map and the warped mask')\n",
        "plt.show()\n",
        "\n",
        "DREAM_MEDIUM_HWLIMIT_nTpV_along_cord=signal_extractor_from_csv(DREAM_MEDIUM_B1mapfile_CVS_HWLIMIT)\n",
        "DREAM_MEDIUM_HWLIMIT_nTpV_along_cord = DREAM_MEDIUM_HWLIMIT_nTpV_along_cord[~np.isnan(DREAM_MEDIUM_HWLIMIT_nTpV_along_cord)] #remove NANs\n",
        "plt.plot(DREAM_MEDIUM_HWLIMIT_nTpV_along_cord)\n",
        "DREAM_MEDIUM_HWLIMIT_nTpV_along_cord_mean=np.round(np.mean(DREAM_MEDIUM_HWLIMIT_nTpV_along_cord))\n",
        "titlestring= f\"B1+ efficiency [nT/V] along the cord in the warped mask. Mean value: {DREAM_MEDIUM_HWLIMIT_nTpV_along_cord_mean}\"\n",
        "plt.title(titlestring)\n",
        "plt.xlabel('Slice along the I-->S direction')\n",
        "plt.ylabel('nT/V')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd0cebf9",
      "metadata": {
        "id": "fd0cebf9"
      },
      "source": [
        "# GRE processing\n",
        "\n",
        "## Here, we grab the individual coil images, and display them in a tiled layout\n",
        "\n",
        "### It could be further adapted to show some kind of metric (CoV?) calculated in the spinal cord mask\n",
        "### Or just showing the spinal cord mask with an almost transparent overlay/outline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406e2e9b",
      "metadata": {
        "id": "406e2e9b"
      },
      "outputs": [],
      "source": [
        "# GRE processing\n",
        "### How many coil uncombined files are there?\n",
        "# Step 1: Setting all the user-defined variables\n",
        "#root_dir='/Users/danielpapp/DATA/Traveling_Spines'\n",
        "#site_name='MGH'\n",
        "#subject_name='SubD'\n",
        "scan_name_GRE='GRE'\n",
        "\n",
        "# Step 2: select individual coil images\n",
        "GRE_PATH = find_scan_dir(root_dir,site_name,subject_name,scan_name_GRE)\n",
        "all_gre_files=sorted(glob.glob(os.path.join(GRE_PATH, '*gre*uncomb*RX*.nii.gz')))\n",
        "gre_phasefiles=sorted(glob.glob(os.path.join(GRE_PATH, '*gre*uncomb*RX*ph*.nii*')))\n",
        "gre_magnitudes=sorted(list(set(all_gre_files)-set(gre_phasefiles)))\n",
        "\n",
        "#Step 3: Tiled figure in a five-row layout\n",
        "numberofgremagfiles=len(gre_magnitudes)\n",
        "numberofrows=5\n",
        "numberofcolumns=int(np.ceil(numberofgremagfiles/numberofrows))\n",
        "\n",
        "fig=plt.figure(figsize=(15, 20))\n",
        "ax = fig.subplots(numberofrows,numberofcolumns,squeeze=True)\n",
        "for rowindex in range(numberofrows):\n",
        "    for columnindex in range(numberofcolumns):\n",
        "        indexoffigure=rowindex*numberofcolumns+columnindex\n",
        "        #read in files\n",
        "        data_to_plot=(nib.load(gre_magnitudes[indexoffigure])).get_fdata() #load in nifti object, get only image data\n",
        "        data_to_plot=np.rot90(data_to_plot[:,:,int(np.ceil(data_to_plot.shape[2]/2))]) #central slice\n",
        "        ax[rowindex,columnindex].imshow(data_to_plot,cmap=plt.cm.gray,clim=[0, 300])\n",
        "        ax[rowindex,columnindex].text(0.5, 0.05, 'Rx channel : ' + str(indexoffigure+1),horizontalalignment='center', transform=ax[rowindex,columnindex].transAxes,color='white',fontsize=20)\n",
        "        ax[rowindex,columnindex].axis('off')\n",
        "\n",
        "plt.axis('off')\n",
        "plt.subplots_adjust(hspace=0,wspace=0)\n",
        "#fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d397619f",
      "metadata": {
        "id": "d397619f"
      },
      "source": [
        "# COILQA PROCESSING\n",
        "\n",
        "## Here we do the following:\n",
        "\n",
        "### First, we find the anatomical scan, the 1/g-factor map and the SNR map\n",
        "\n",
        "### Second, we split the 1/g factor map into its 12 components, and we likewise split the SNR map\n",
        "\n",
        "### Third, we crop the split maps using the anatomical (otherwise we would have to deal with 512x512 images)\n",
        "\n",
        "### Forth, we visualize the 1/g factor map in a tiled layout, similar to the GRE scan\n",
        "\n",
        "### Fifth, we coregister the CoilQA anatomical to the MP2RAGE scan, warp the mask to the CoilQA space, and extract the SNR along the spinal cord (Extracting does not work yet, because the cropping results in a 255x256 image insteead of a 256x256 one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c065c0",
      "metadata": {
        "id": "c8c065c0"
      },
      "outputs": [],
      "source": [
        "# Step 1: User defined paths and varaibles\n",
        "#root_dir='/Users/danielpapp/DATA/Traveling_Spines'\n",
        "#site_name='MGH'\n",
        "#subject_name='SubD'\n",
        "scan_name_COILQA_SAG_LARGE='COILQA_SAG_LARGE'\n",
        "\n",
        "# Step 2: select the anatomical, SNR map and 1/g-factor maps\n",
        "COILQA_SAG_LARGE_PATH = find_scan_dir(root_dir,site_name,subject_name,scan_name_COILQA_SAG_LARGE)\n",
        "# Because there is no way to discriminate the anatomical based on JSON data (in brief, the anatomical is the only\n",
        "# one that does NOT have an ImageComments field, but everything else is identical), we have to basically list\n",
        "# all nifti files and remove the identified SNRmap, 1/g factor map and Noise Covariance matrix\n",
        "COILQA_SAG_LARGE_GFACTOR = find_matching_nii_json_pairs(COILQA_SAG_LARGE_PATH, 'R=2', 'ImageComments')[-1]\n",
        "COILQA_SAG_LARGE_SNRMAP = find_matching_nii_json_pairs(COILQA_SAG_LARGE_PATH, 'SNR', 'ImageComments')[-1]\n",
        "COILQA_SAG_LARGE_COVARIANCE = find_matching_nii_json_pairs(COILQA_SAG_LARGE_PATH, 'mag', 'ImageComments')[-1]\n",
        "all_nifties_in_dir=sorted(glob.glob(os.path.join(COILQA_SAG_LARGE_PATH, '*coilQA*.nii.gz')))\n",
        "COILQA_SAG_LARGE_ANAT=sorted(list(set(all_nifties_in_dir)-set([COILQA_SAG_LARGE_GFACTOR,COILQA_SAG_LARGE_SNRMAP,COILQA_SAG_LARGE_COVARIANCE])))[-1]\n",
        "\n",
        "# Step 3: Predefine filenames and paths for PROCESSING\n",
        "COILQA_SAG_LARGE_PROCESSING_PATH=os.path.join(root_dir,'Processing',site_name,subject_name,scan_name_COILQA_SAG_LARGE)\n",
        "if not os.path.isdir(COILQA_SAG_LARGE_PROCESSING_PATH):\n",
        "    os.makedirs(COILQA_SAG_LARGE_PROCESSING_PATH)\n",
        "\n",
        "QCfilepath_COILQA_SAG_LARGE=os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,'qc')\n",
        "SNR_splitname=os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,COILQA_SAG_LARGE_SNRMAP.split('.')[0].split('/')[-1]+'_SNRsplit.nii.gz')\n",
        "GFACTOR_splitname=os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,COILQA_SAG_LARGE_GFACTOR.split('.')[0].split('/')[-1]+'_Gfactorsplit.nii.gz')\n",
        "COILQA_SAG_LARGE_warp_2_MP2RAGEfilename=os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,COILQA_SAG_LARGE_ANAT.split('.')[0].split('/')[-1]+'_warp_2_MP2RAGE.nii.gz')\n",
        "warpMP2RAGE_2_COILQA_SAG_LARGEfilename=os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,COILQA_SAG_LARGE_ANAT.split('.')[0].split('/')[-1]+'_warp_MP2RAGE_2_COILQA_LARGE_SAG.nii.gz')\n",
        "warpedmaskname_COILQA_SAG_LARGE=os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,COILQA_SAG_LARGE_ANAT.split('.')[0].split('/')[-1]+'_MP2RAGE_mask_warped.nii.gz')\n",
        "COILQA_SAG_LARGE_SNR_OPT_CSV=os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,COILQA_SAG_LARGE_ANAT.split('.')[0].split('/')[-1]+'_SNR_Opt.csv')\n",
        "COILQA_SAG_LARGE_SNR_RSS_CSV=os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,COILQA_SAG_LARGE_ANAT.split('.')[0].split('/')[-1]+'_SNR_RSS.csv')\n",
        "#DREAM_MEDIUM_B1mapfile_CVS_HWLIMIT=os.path.join(DREAM_MEDIUM_PROCESSING_PATH_HWLIMIT,DREAM_MEDIUM_anatfile_HWLIMIT.split('.')[0].split('/')[-1]+'_nTpV.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "375a6b41",
      "metadata": {
        "id": "375a6b41"
      },
      "outputs": [],
      "source": [
        "# Step 4: Splitting and cropping SNR map\n",
        "# Removing exsisting files for cleanup (otherwise we end up with _cropped_cropped_cropped...)\n",
        "SNRmap_splitnames=(SNR_splitname.split('/')[-1]).split('.')[0]+'*T*'\n",
        "SNRmap_splitfiles=sorted(glob.glob(os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,SNRmap_splitnames)))\n",
        "if (SNRmap_splitfiles):\n",
        "  print('Removing exsisting split files for safety')\n",
        "  for index in range(len(SNRmap_splitfiles)):\n",
        "    os.remove(SNRmap_splitfiles[index])\n",
        "# Splitting\n",
        "run_subprocess(f\"sct_image -i {COILQA_SAG_LARGE_SNRMAP} -split t -o {SNR_splitname}\")\n",
        "SNRmap_splitfiles=sorted(glob.glob(os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,SNRmap_splitnames)))\n",
        "# Cropping\n",
        "SNRmap_split_cropped_name=[None]*len(SNRmap_splitfiles)\n",
        "for index in range(len(SNRmap_splitfiles)):\n",
        "    SNRmap_split_cropped_name[index]=(SNRmap_splitfiles[index]).split('.')[0]+'_cropped.nii.gz'\n",
        "    run_subprocess(f\"sct_register_multimodal -i {SNRmap_splitfiles[index]} -d {COILQA_SAG_LARGE_ANAT} -o {SNRmap_split_cropped_name[index]} -identity 1\")\n",
        "\n",
        "# Step 5: Splitting and cropping 1/g factor map\n",
        "# Removing exsisting files for cleanup (otherwise we end up with _cropped_cropped_cropped...)\n",
        "GFACTOR_splitnames=(GFACTOR_splitname.split('/')[-1]).split('.')[0]+'*T*'\n",
        "GFACTOR_splitfiles=sorted(glob.glob(os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,GFACTOR_splitnames)))\n",
        "if (GFACTOR_splitfiles):\n",
        "  print('Removing exsisting split files for safety')\n",
        "  for index in range(len(GFACTOR_splitfiles)):\n",
        "    os.remove(GFACTOR_splitfiles[index])\n",
        "# Splitting\n",
        "run_subprocess(f\"sct_image -i {COILQA_SAG_LARGE_GFACTOR} -split t -o {GFACTOR_splitname}\")\n",
        "GFACTOR_splitnames=(GFACTOR_splitname.split('/')[-1]).split('.')[0]+'*T*'\n",
        "GFACTOR_splitfiles=sorted(glob.glob(os.path.join(COILQA_SAG_LARGE_PROCESSING_PATH,GFACTOR_splitnames)))\n",
        "# Cropping\n",
        "GFACTOR_split_cropped_name=[None]*len(GFACTOR_splitfiles)\n",
        "for index in range(len(GFACTOR_splitfiles)):\n",
        "    GFACTOR_split_cropped_name[index]=(GFACTOR_splitfiles[index]).split('.')[0]+'_cropped.nii.gz'\n",
        "    run_subprocess(f\"sct_register_multimodal -i {GFACTOR_splitfiles[index]} -d {COILQA_SAG_LARGE_ANAT} -o {GFACTOR_split_cropped_name[index]} -identity 1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8752fc2",
      "metadata": {
        "id": "d8752fc2"
      },
      "outputs": [],
      "source": [
        "# Step 6: Coregister the CoilQA anatomical to the MP2RAGE and extract the SNR along the spinal cord\n",
        "# First, lets make sure that the results from the MP2RAGE processing exist\n",
        "[MP2RAGE_UNI_filename,MP2RAGE_UNI_maskfilename]=MP2RAGE_checker(root_dir,site_name,subject_name,scan_name_COILQA_SAG_LARGE)\n",
        "\n",
        "# Then, lets coregister the scans\n",
        "#run_subprocess(f\"sct_register_multimodal -i {COILQA_SAG_LARGE_ANAT} -d {MP2RAGE_UNI_filename} -ofolder {COILQA_SAG_LARGE_PROCESSING_PATH} -owarp {COILQA_SAG_LARGE_warp_2_MP2RAGEfilename} -owarpinv {warpMP2RAGE_2_COILQA_SAG_LARGEfilename} -qc {QCfilepath_COILQA_SAG_LARGE}\")\n",
        "run_subprocess(f\"sct_register_multimodal -d {COILQA_SAG_LARGE_ANAT} -i {MP2RAGE_UNI_filename} -ofolder {COILQA_SAG_LARGE_PROCESSING_PATH} -owarp {warpMP2RAGE_2_COILQA_SAG_LARGEfilename} -qc {QCfilepath_COILQA_SAG_LARGE}\")\n",
        "\n",
        "# Apply the warp to the mask\n",
        "run_subprocess(f\"sct_apply_transfo -i {MP2RAGE_UNI_maskfilename} -d {COILQA_SAG_LARGE_ANAT} -w {warpMP2RAGE_2_COILQA_SAG_LARGEfilename} -o {warpedmaskname_COILQA_SAG_LARGE} -x nn\")\n",
        "\n",
        "# And extract metrics\n",
        "# NB! 0 is the SNR optimal reconstruction, 1 is the Root-Sum-of-Squares\n",
        "# NB! this does not work yet: https://forum.spinalcordmri.org/t/sct-crop-image-ref-result-is-one-pixel-smaller/\n",
        "run_subprocess(f\"sct_extract_metric -i {SNRmap_split_cropped_name[1]} -f {warpedmaskname_COILQA_SAG_LARGE} -perslice 1 -o {COILQA_SAG_LARGE_SNR_OPT_CSV}\")\n",
        "run_subprocess(f\"sct_extract_metric -i {SNRmap_split_cropped_name[0]} -f {warpedmaskname_COILQA_SAG_LARGE} -perslice 1 -o {COILQA_SAG_LARGE_SNR_RSS_CSV}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84691dda",
      "metadata": {
        "id": "84691dda"
      },
      "outputs": [],
      "source": [
        "## Step 7: Visualising the 1/g factor map (like with the GRE scan)\n",
        "numberofrows=3\n",
        "numberofcolumns=4\n",
        "\n",
        "fig=plt.figure(figsize=(15, 13))\n",
        "text_for_figure=['R 2','R 3', 'R 4', 'R 6', 'R 8', 'R 2 x 2',\n",
        "                 'R 2 x 3', 'R 3 x 2', 'R 3 x 3', 'R 3 x 4', 'R 4 x 3', 'R 4 x 4']\n",
        "ax = fig.subplots(numberofrows,numberofcolumns,squeeze=True)\n",
        "for rowindex in range(numberofrows):\n",
        "    for columnindex in range(numberofcolumns):\n",
        "        indexoffigure=rowindex*numberofcolumns+columnindex\n",
        "        #read in files\n",
        "        data_to_plot=(nib.load(GFACTOR_split_cropped_name[indexoffigure])).get_fdata() #load in nifti object, get only image data\n",
        "        data_to_plot=np.rot90(data_to_plot[:,:,int(np.ceil(data_to_plot.shape[2]/2))]) #central slice\n",
        "        ax[rowindex,columnindex].imshow(data_to_plot,cmap=plt.cm.hot,clim=[0, 1000])\n",
        "        ax[rowindex,columnindex].text(0.5, 0.05, text_for_figure[indexoffigure],horizontalalignment='center', transform=ax[rowindex,columnindex].transAxes,color='black',fontsize=20)\n",
        "        ax[rowindex,columnindex].axis('off')\n",
        "\n",
        "plt.axis('off')\n",
        "plt.subplots_adjust(hspace=0,wspace=0)\n",
        "#fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Plotting the SNR\n",
        "\n",
        "SNR_along_cord = signal_extractor_from_csv(COILQA_SAG_LARGE_SNR_OPT_CSV)\n",
        "SNR_along_cord = SNR_along_cord[~np.isnan(SNR_along_cord)]\n",
        "\n",
        "plt.plot(SNR_along_cord)\n",
        "SNR_along_cord_mean = np.round(np.mean(SNR_along_cord))\n",
        "titlestring = f\"SNR along the cord. Mean value: {SNR_along_cord_mean}\"\n",
        "plt.title(titlestring)\n",
        "plt.xlabel('Slice along the I-->S direction')\n",
        "plt.ylabel('SNR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ux8SWk-xfhp6"
      },
      "id": "ux8SWk-xfhp6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}